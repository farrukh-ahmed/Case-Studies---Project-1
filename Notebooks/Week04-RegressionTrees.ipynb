{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Studies\n",
    "\n",
    "Project: 1\n",
    "\n",
    "Group: 3\n",
    "\n",
    "Group Members:\n",
    " - Muhammad Raafey Tariq (231806)\n",
    " - Farrukh Ahmed (230614)\n",
    " - Amirreza Khamehchin Khiabani (230891)\n",
    " - Aymane Hachcham (236392)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    " - numpy==1.24.2\n",
    " - matplotlib==3.7.1\n",
    " - seaborn==0.12.2\n",
    " - pandas==2.0.0\n",
    " - openpyxl==3.1.2\n",
    "\n",
    "Installation Commands (One-time only)\n",
    " - pip install pandas==2.0.0\n",
    " - pip install numpy==1.24.2\n",
    " - pip install seaborn==0.12.2\n",
    " - pip install matplotlib==3.7.1\n",
    " - pip install openpyxl==3.1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "# used for the graphs\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "sns.set(font_scale = 1.2)\n",
    "\n",
    "# used for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# setting font to 'Times New Roman'\n",
    "matplotlib.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables and Constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raafe\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "data_df = read_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformating Columns to Correct Data Types and dropping nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that are dropped \n",
    "to_filter = [\"id\", \"zeit\", \"postleitzahl\", \"gemeinde\", \"bezirk\", \"geburtsjahr\", \"schaetzwert_bp_sys\", \"schaetzwert_by_dia\", \"terminal\"]\n",
    "data_df, cat_feat_list, num_feat_list = format_variables(data_df, to_filter=to_filter, drop_values=True)\n",
    "\n",
    "# one hot encoding cat variables to prep data for Decision Tree\n",
    "# ordinal variables and nominal are treated the same in trees, but need to be careful in Lin models\n",
    "\n",
    "encoded_data_df = encode_data(data_df, cat_feat_list, num_feat_list)\n",
    "encoded_train_set, encoded_test_set = train_test_split(encoded_data_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  10381\n",
      "Size of testing data:  4450\n",
      "Features used:  Index(['bundesland', 'befinden', 'geschlecht', 'raucher', 'blutzucker_bekannt',\n",
      "       'cholesterin_bekannt', 'in_behandlung', 'schaetzwert_bp_sys',\n",
      "       'schaetzwert_by_dia', 'messwert_bp_sys', 'messwert_bp_dia', 'age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data: \", len(encoded_train_set))\n",
    "print(\"Size of testing data: \", len(encoded_test_set))\n",
    "print(\"Features used: \", data_df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    " - scikit-learn uses an optimized version of the CART algorithm, does not support categorical variables\n",
    " - BIC cannot be computed as it depends on likelihood, cannot compute that for RegressionTree as it does not assume a conditional dist of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using self evaluated sys bp for analysis\n",
    "target = \"messwert_bp_sys\"\n",
    "\n",
    "# splitting targets from predictors\n",
    "X_train, Y_train = separate_target(encoded_train_set, target)\n",
    "X_test, Y_test = separate_target(encoded_test_set, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for DecisonTreeRegressor using all available features and default parameters\n",
    "\n",
    "train_results_tree_base, test_results_tree_base, model_tree_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\", params={\"criterion\" : \"squared_error\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for RandomForestRegressor using all available features and default parameters\n",
    "\n",
    "train_results_rf_base, test_results_rf_base, model_rf_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\", {\"criterion\" : \"squared_error\",\n",
    "                                                                                                                    \"n_estimators\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [1, 6, 11, 16, 21],\n",
       "                         'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         'min_weight_fraction_leaf': [0.0],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the best set of parameters to use by finetuning RegTree using CV, fine-tuning is done on whole dataset\n",
    "\n",
    "parameters= {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : list(np.arange(1, 25, 5, dtype=int)),\n",
    "           \"min_samples_leaf\":list(np.arange(1, 100, 5, dtype=int)),\n",
    "           \"min_weight_fraction_leaf\":list(np.arange(0, 1, 1.0, dtype=float)),\n",
    "           \"max_features\":list(np.arange(1, len(X_train.columns), 1, dtype=int))\n",
    "           }\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "X_train_full, Y_train_full = separate_target(encoded_data_df, target)\n",
    "tuning_model = GridSearchCV(model, param_grid=parameters, scoring='neg_mean_squared_error',cv=10,verbose=0)\n",
    "tuning_model.fit(X_train_full, Y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'max_features': 20,\n",
       " 'min_samples_leaf': 66,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for DecisonTreeRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "\n",
    "train_results_tree_fine, test_results_tree_fine, model_tree_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for RandomForestRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "del model_params[\"splitter\"]\n",
    "model_params[\"n_estimators\"] = 100\n",
    "\n",
    "train_results_rf_fine, test_results_rf_fine, model_rf_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Mean Sq Error</th>\n",
       "      <th>Test Mean Sq Error</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train Adjusted R2</th>\n",
       "      <th>Test Adjusted R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree (Base)</td>\n",
       "      <td>1.236</td>\n",
       "      <td>358.492</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree (Fine-tuned)</td>\n",
       "      <td>162.762</td>\n",
       "      <td>186.525</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree (Best Subset + Base)</td>\n",
       "      <td>201.705</td>\n",
       "      <td>210.619</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree (Best Subset + Fine-tuned)</td>\n",
       "      <td>163.631</td>\n",
       "      <td>185.668</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF (Base)</td>\n",
       "      <td>25.893</td>\n",
       "      <td>190.671</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF (Fine-tuned)</td>\n",
       "      <td>161.505</td>\n",
       "      <td>177.671</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF (Best Subset + Base)</td>\n",
       "      <td>25.826</td>\n",
       "      <td>190.375</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF (Best Subset + Fine-tuned)</td>\n",
       "      <td>161.370</td>\n",
       "      <td>177.851</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Train Mean Sq Error  Test Mean Sq Error   \n",
       "0                      Tree (Base)                1.236             358.492  \\\n",
       "1                Tree (Fine-tuned)              162.762             186.525   \n",
       "2        Tree (Best Subset + Base)              201.705             210.619   \n",
       "3  Tree (Best Subset + Fine-tuned)              163.631             185.668   \n",
       "4                        RF (Base)               25.893             190.671   \n",
       "5                  RF (Fine-tuned)              161.505             177.671   \n",
       "6          RF (Best Subset + Base)               25.826             190.375   \n",
       "7    RF (Best Subset + Fine-tuned)              161.370             177.851   \n",
       "\n",
       "   Train R2  Test R2  Train Adjusted R2  Test Adjusted R2  \n",
       "0     0.997    0.041              0.997             0.037  \n",
       "1     0.558    0.501              0.557             0.499  \n",
       "2     0.452    0.437              0.452             0.437  \n",
       "3     0.556    0.504              0.556             0.503  \n",
       "4     0.930    0.490              0.930             0.488  \n",
       "5     0.562    0.525              0.561             0.523  \n",
       "6     0.930    0.491              0.930             0.489  \n",
       "7     0.562    0.524              0.561             0.523  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_list = [train_results_tree_base, train_results_tree_fine, train_results_rf_base, train_results_rf_fine]\n",
    "\n",
    "test_result_list = [test_results_tree_base, test_results_tree_fine, test_results_rf_base, test_results_rf_fine]\n",
    "\n",
    "model_names = [\"Tree (Base)\", \"Tree (Fine-tuned)\",\n",
    "               \"RF (Base)\", \"RF (Fine-tuned)\"]\n",
    "\n",
    "tab = tabularize_model_metrics(train_result_list, test_result_list, model_names)\n",
    "round(tab, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      " & Model & Train Mean Sq Error & Test Mean Sq Error & Train R2 & Test R2 & Train Adjusted R2 & Test Adjusted R2 \\\\\n",
      "\\midrule\n",
      "0 & Tree (Base) & 1.240000 & 358.490000 & 1.000000 & 0.040000 & 1.000000 & 0.040000 \\\\\n",
      "1 & Tree (Fine-tuned) & 162.760000 & 186.530000 & 0.560000 & 0.500000 & 0.560000 & 0.500000 \\\\\n",
      "2 & Tree (Best Subset + Base) & 201.700000 & 210.620000 & 0.450000 & 0.440000 & 0.450000 & 0.440000 \\\\\n",
      "3 & Tree (Best Subset + Fine-tuned) & 163.630000 & 185.670000 & 0.560000 & 0.500000 & 0.560000 & 0.500000 \\\\\n",
      "4 & RF (Base) & 25.890000 & 190.670000 & 0.930000 & 0.490000 & 0.930000 & 0.490000 \\\\\n",
      "5 & RF (Fine-tuned) & 161.510000 & 177.670000 & 0.560000 & 0.520000 & 0.560000 & 0.520000 \\\\\n",
      "6 & RF (Best Subset + Base) & 25.830000 & 190.380000 & 0.930000 & 0.490000 & 0.930000 & 0.490000 \\\\\n",
      "7 & RF (Best Subset + Fine-tuned) & 161.370000 & 177.850000 & 0.560000 & 0.520000 & 0.560000 & 0.520000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(round(tab, 2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using self evaluated dia bp for analysis\n",
    "target = \"messwert_bp_dia\"\n",
    "\n",
    "# splitting targets from predictors\n",
    "X_train, Y_train = separate_target(encoded_train_set, target)\n",
    "X_test, Y_test = separate_target(encoded_test_set, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for DecisonTreeRegressor using all available features and default parameters\n",
    "\n",
    "train_results_tree_base, test_results_tree_base, model_tree_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\", {\"criterion\" : \"squared_error\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for RandomForestRegressor using all available features and default parameters\n",
    "\n",
    "train_results_rf_base, test_results_rf_base, model_rf_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\", {\"criterion\" : \"squared_error\",\n",
    "                                                                                                                    \"n_estimators\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [1, 6, 11, 16, 21],\n",
       "                         'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         'min_weight_fraction_leaf': [0.0],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the best set of parameters to use by finetuning RegTree using CV, fine-tuning is done on whole dataset\n",
    "\n",
    "parameters= {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : list(np.arange(1, 25, 5, dtype=int)),\n",
    "           \"min_samples_leaf\":list(np.arange(1, 100, 5, dtype=int)),\n",
    "           \"min_weight_fraction_leaf\":list(np.arange(0, 1, 1.0, dtype=float)),\n",
    "           \"max_features\":list(np.arange(1, len(X_train.columns), 1, dtype=int))\n",
    "           }\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "X_train_full, Y_train_full = separate_target(encoded_data_df, target)\n",
    "tuning_model = GridSearchCV(model, param_grid=parameters, scoring='neg_mean_squared_error',cv=10,verbose=0)\n",
    "tuning_model.fit(X_train_full, Y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 21,\n",
       " 'min_samples_leaf': 11,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for DecisonTreeRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "\n",
    "train_results_tree_fine, test_results_tree_fine, model_tree_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for RandomForestRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "del model_params[\"splitter\"]\n",
    "model_params[\"n_estimators\"] = 100\n",
    "\n",
    "train_results_rf_fine, test_results_rf_fine, model_rf_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Mean Sq Error</th>\n",
       "      <th>Test Mean Sq Error</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train Adjusted R2</th>\n",
       "      <th>Test Adjusted R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree (Base)</td>\n",
       "      <td>0.492</td>\n",
       "      <td>217.605</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree (Fine-tuned)</td>\n",
       "      <td>100.353</td>\n",
       "      <td>105.504</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree (Best Subset + Base)</td>\n",
       "      <td>109.183</td>\n",
       "      <td>117.472</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree (Best Subset + Fine-tuned)</td>\n",
       "      <td>100.327</td>\n",
       "      <td>105.647</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF (Base)</td>\n",
       "      <td>15.950</td>\n",
       "      <td>114.534</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF (Fine-tuned)</td>\n",
       "      <td>97.315</td>\n",
       "      <td>103.097</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF (Best Subset + Base)</td>\n",
       "      <td>16.046</td>\n",
       "      <td>114.819</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF (Best Subset + Fine-tuned)</td>\n",
       "      <td>97.226</td>\n",
       "      <td>103.153</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Train Mean Sq Error  Test Mean Sq Error   \n",
       "0                      Tree (Base)                0.492             217.605  \\\n",
       "1                Tree (Fine-tuned)              100.353             105.504   \n",
       "2        Tree (Best Subset + Base)              109.183             117.472   \n",
       "3  Tree (Best Subset + Fine-tuned)              100.327             105.647   \n",
       "4                        RF (Base)               15.950             114.534   \n",
       "5                  RF (Fine-tuned)               97.315             103.097   \n",
       "6          RF (Best Subset + Base)               16.046             114.819   \n",
       "7    RF (Best Subset + Fine-tuned)               97.226             103.153   \n",
       "\n",
       "   Train R2  Test R2  Train Adjusted R2  Test Adjusted R2  \n",
       "0     0.998   -0.104              0.998            -0.110  \n",
       "1     0.505    0.465              0.504             0.462  \n",
       "2     0.461    0.404              0.461             0.404  \n",
       "3     0.505    0.464              0.504             0.463  \n",
       "4     0.921    0.419              0.921             0.416  \n",
       "5     0.520    0.477              0.519             0.474  \n",
       "6     0.921    0.417              0.921             0.415  \n",
       "7     0.520    0.477              0.519             0.475  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_list = [train_results_tree_base, train_results_tree_fine, train_results_rf_base, train_results_rf_fine]\n",
    "\n",
    "test_result_list = [test_results_tree_base, test_results_tree_fine, test_results_rf_base, test_results_rf_fine]\n",
    "\n",
    "model_names = [\"Tree (Base)\", \"Tree (Fine-tuned)\", \"RF (Base)\", \"RF (Fine-tuned)\"]\n",
    "\n",
    "tab = tabularize_model_metrics(train_result_list, test_result_list, model_names)\n",
    "round(tab, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      " & Model & Train Mean Sq Error & Test Mean Sq Error & Train R2 & Test R2 & Train Adjusted R2 & Test Adjusted R2 \\\\\n",
      "\\midrule\n",
      "0 & Tree (Base) & 0.490000 & 217.600000 & 1.000000 & -0.100000 & 1.000000 & -0.110000 \\\\\n",
      "1 & Tree (Fine-tuned) & 100.350000 & 105.500000 & 0.500000 & 0.460000 & 0.500000 & 0.460000 \\\\\n",
      "2 & Tree (Best Subset + Base) & 109.180000 & 117.470000 & 0.460000 & 0.400000 & 0.460000 & 0.400000 \\\\\n",
      "3 & Tree (Best Subset + Fine-tuned) & 100.330000 & 105.650000 & 0.500000 & 0.460000 & 0.500000 & 0.460000 \\\\\n",
      "4 & RF (Base) & 15.950000 & 114.530000 & 0.920000 & 0.420000 & 0.920000 & 0.420000 \\\\\n",
      "5 & RF (Fine-tuned) & 97.310000 & 103.100000 & 0.520000 & 0.480000 & 0.520000 & 0.470000 \\\\\n",
      "6 & RF (Best Subset + Base) & 16.050000 & 114.820000 & 0.920000 & 0.420000 & 0.920000 & 0.410000 \\\\\n",
      "7 & RF (Best Subset + Fine-tuned) & 97.230000 & 103.150000 & 0.520000 & 0.480000 & 0.520000 & 0.470000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(round(tab, 2).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
