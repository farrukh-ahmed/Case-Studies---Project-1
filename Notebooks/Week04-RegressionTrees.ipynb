{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Studies\n",
    "\n",
    "Project: 1\n",
    "\n",
    "Group: 3\n",
    "\n",
    "Group Members:\n",
    " - Muhammad Raafey Tariq (231806)\n",
    " - Farrukh Ahmed (230614)\n",
    " - Amirreza Khamehchin Khiabani (230891)\n",
    " - Aymane Hachcham (236392)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    " - numpy==1.24.2\n",
    " - matplotlib==3.7.1\n",
    " - seaborn==0.12.2\n",
    " - pandas==2.0.0\n",
    " - openpyxl==3.1.2\n",
    "\n",
    "Installation Commands (One-time only)\n",
    " - pip install pandas==2.0.0\n",
    " - pip install numpy==1.24.2\n",
    " - pip install seaborn==0.12.2\n",
    " - pip install matplotlib==3.7.1\n",
    " - pip install openpyxl==3.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "# used for the graphs\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "sns.set(font_scale = 1.2)\n",
    "\n",
    "# used for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# setting font to 'Times New Roman'\n",
    "matplotlib.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables and Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raafe\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../styrian_health_data.xlsx\"\n",
    "sheet_name = \"Sheet 1\"\n",
    "data_df = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformating Columns to Correct Data Types and dropping nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format variable types, remove nans, shuffle data\n",
    "def format_variables(data, to_filter=[]):\n",
    "    data_df = data.copy()\n",
    "    data_df.postleitzahl = data_df.postleitzahl.astype('str')\n",
    "    data_df.geburtsjahr = data_df.geburtsjahr.astype('Int64')\n",
    "    # data_df.befinden = data_df.befinden.astype('Int64')\n",
    "    data_df.messwert_bp_sys = pd.to_numeric(data_df.messwert_bp_sys)\n",
    "    data_df.messwert_bp_dia = pd.to_numeric(data_df.messwert_bp_dia)\n",
    "    data_df.schaetzwert_bp_sys = pd.to_numeric(data_df.schaetzwert_bp_sys)\n",
    "    data_df.schaetzwert_by_dia = pd.to_numeric(data_df.schaetzwert_by_dia)\n",
    "\n",
    "    # adding variable for is_local\n",
    "    mask = data_df.gemeinde.isna() & data_df.bezirk.isna() & data_df.bundesland.isna()\n",
    "    data_df[\"is_local_resident\"] = True\n",
    "    data_df.loc[mask, \"is_local_resident\"] = False\n",
    "\n",
    "    # adding variable for age\n",
    "    age =  data_df[\"zeit\"].dt.year - pd.to_datetime(data_df['geburtsjahr'], format='%Y').dt.year\n",
    "    data_df[\"age\"] = age.astype(\"Int64\")\n",
    "\n",
    "    # adding variable for age group\n",
    "    data_df[\"age_group\"] = pd.cut(data_df.age, bins=[0,12,19,65,130],labels=['children', 'teenager', 'adult','65 over'])\n",
    "    data_df[\"age_group\"] = data_df.age_group.astype(str)\n",
    "\n",
    "    #replacing nans for variables\n",
    "\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'raucher'] = \"unknown\"\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'blutzucker_bekannt'] = \"unknown\"\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'cholesterin_bekannt'] = \"unknown\"\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'in_behandlung'] = \"unknown\"\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'befinden'] = \"unknown\"\n",
    "    data_df.loc[data_df.age_group == \"nan\", 'age_group'] = \"unknown\"\n",
    "\n",
    "    data_df.loc[mask, 'gemeinde'] = \"not applicable\"\n",
    "    data_df.loc[mask, 'bezirk'] = \"not applicable\"\n",
    "    data_df.loc[mask, 'bundesland'] = \"not applicable\"\n",
    "    data_df.loc[mask, 'postleitzahl'] = \"not applicable\"\n",
    "    data_df.loc[data_df.postleitzahl == \"nan\", 'postleitzahl'] = \"unknown\"\n",
    "\n",
    "    # creating variables for missing values in bp\n",
    "\n",
    "    data_df[\"is_missing_schaetzwert_bp_sys\"] = False\n",
    "    data_df.loc[data_df.schaetzwert_bp_sys.isna() == True, \"is_missing_schaetzwert_bp_sys\"] = True\n",
    "    data_df[\"is_missing_schaetzwert_by_dia\"] = False\n",
    "    data_df.loc[data_df.schaetzwert_by_dia.isna() == True, \"is_missing_schaetzwert_by_dia\"] = True\n",
    "\n",
    "    # removing useless variables\n",
    "    data_df.drop(data_df[data_df.age > 100].index, inplace=True)\n",
    "    data_df.drop(data_df[data_df.age < 15].index, inplace=True)\n",
    "\n",
    "    data_df.loc[data_df.geschlecht.isna() == True, 'geschlecht'] = \"unknown\"\n",
    "\n",
    "    data_df = data_df.dropna()\n",
    "\n",
    "    if len(to_filter) > 0:\n",
    "        data_df = data_df.drop(to_filter, axis=1)\n",
    "\n",
    "    data_df.befinden = data_df.befinden.astype('Int64')\n",
    "\n",
    "    data_df['befinden'] = data_df['befinden'].astype(object)\n",
    "    data_df['messwert_bp_sys'] = data_df['messwert_bp_sys'].astype(float)\n",
    "    data_df['messwert_bp_dia'] = data_df['messwert_bp_dia'].astype(float)\n",
    "    data_df['geschlecht'] = data_df['geschlecht'].astype(object)\n",
    "    data_df['is_local_resident'] = data_df['is_local_resident'].astype(object)\n",
    "\n",
    "    # shuffling data with fixed seed\n",
    "    data_df = data_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # separating var types\n",
    "    cat_feat_list = []\n",
    "    num_feat_list = []\n",
    "\n",
    "    for var in data_df.columns:\n",
    "        if data_df[var].dtype == object:\n",
    "            cat_feat_list.append(var)\n",
    "        else:\n",
    "            num_feat_list.append(var)\n",
    "\n",
    "    return data_df, cat_feat_list, num_feat_list\n",
    "\n",
    "\n",
    "# function that converts cat columns in df to one-hot encoding\n",
    "def encode_data(df, cat_feat_list, num_feat_list):\n",
    "    one_hot_data = pd.get_dummies(df[cat_feat_list], drop_first=True, dtype=int)\n",
    "\n",
    "    for var in num_feat_list:\n",
    "        one_hot_data[var] = df[var] \n",
    "    \n",
    "    return one_hot_data\n",
    "\n",
    "# function to separate target from dataframe\n",
    "def separate_target(data, target):\n",
    "    df = data.copy()\n",
    "    Y = df[target]\n",
    "    del df[target]\n",
    "    X = df\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# computes adjusted R2\n",
    "def adjusted_r2(r_2, n, k):\n",
    "    return 1 - (1-r_2)*(n-1)/(n-k-1)\n",
    "\n",
    "\n",
    "# function to compute metrics given target and predictions\n",
    "def compute_metrics(pred, target, num_feats):\n",
    "    r_2 = r2_score(pred, target)\n",
    "    mse = mean_squared_error(pred, target)\n",
    "    adj_r2 = adjusted_r2(r_2, len(pred), num_feats)\n",
    "    return {\n",
    "        \"r_2\": r_2,\n",
    "        \"adjusted_r_2\": adj_r2,\n",
    "        \"mse\": mse\n",
    "    }\n",
    "\n",
    "# method that fits and predicts regression tree based on model type\n",
    "def fit_and_eval_regression_tree(X_train, Y_train, X_test, params, model_type):\n",
    "    model = None\n",
    "    if model_type == \"DecisionTreeRegressor\":\n",
    "        model = DecisionTreeRegressor(**params)\n",
    "    elif model_type == \"DecisionTreeRegressorRandomForest\":\n",
    "        model = RandomForestRegressor(**params)\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return train_predictions, test_predictions, model\n",
    "\n",
    "# method that fits, predicts, generates eval metrics for regression tree based on model type\n",
    "def fit_model(X_train, Y_train, X_test, Y_test, model_type, params):\n",
    "    num_feats = len(X_train.columns)\n",
    "    train_predictions = None\n",
    "    train_predictions = None\n",
    "    train_results = None\n",
    "    test_results = None\n",
    "    model = None\n",
    "\n",
    "    if model_type in [\"DecisionTreeRegressor\", \"DecisionTreeRegressorRandomForest\"]:\n",
    "        train_predictions, test_predictions, model = fit_and_eval_regression_tree(X_train, Y_train, X_test, params, model_type)\n",
    "\n",
    "    if train_predictions is not None and test_predictions is not None:\n",
    "        train_results = compute_metrics(train_predictions, Y_train, num_feats)\n",
    "        test_results = compute_metrics(test_predictions, Y_test, num_feats)\n",
    "\n",
    "\n",
    "    return train_results, test_results, model\n",
    "\n",
    "# method that performs best subset feat selection based on some creiterion like mse, adjusted_r_2 or r_2\n",
    "def best_subset_selection(features, criterion, X_train, Y_train, X_test, Y_test, model_type, params, verbose):\n",
    "    if criterion == \"mse\":\n",
    "        best_val = np.inf\n",
    "    elif criterion in [\"adjusted_r_2\", \"r_2\"]:\n",
    "        best_val = -np.inf\n",
    "\n",
    "    best_train_results = None\n",
    "    best_model = None\n",
    "    best_test_results = None\n",
    "    best_features = None\n",
    "    n_features = len(features)\n",
    "\n",
    "\n",
    "    for i in range(1, n_features):\n",
    "        if verbose > 1:\n",
    "            print(\"\\nNum features: \", i, \"=======================================================\")\n",
    "\n",
    "        for j in range(n_features):\n",
    "            current_features = features[j:j+i]\n",
    "            if len(current_features) < i:\n",
    "                break\n",
    "\n",
    "            X_train_curr = X_train[current_features]\n",
    "            X_test_curr = X_test[current_features]\n",
    "            \n",
    "            train_results, test_results, model = fit_model(X_train_curr, Y_train, X_test_curr, Y_test, model_type, params)\n",
    "\n",
    "            if verbose > 1:\n",
    "                print(\"\\nFeatures: \", current_features)\n",
    "                print(\"Train Results: \", train_results)\n",
    "                print(\"Test Results: \", test_results)\n",
    "\n",
    "            condition = False\n",
    "            if criterion == \"mse\":\n",
    "                condition = test_results[criterion] < best_val\n",
    "            elif criterion in [\"adjusted_r_2\", \"r_2\"]:\n",
    "                condition = test_results[criterion] > best_val   \n",
    "\n",
    "            if condition:\n",
    "                best_val = test_results[criterion]\n",
    "                best_model = model\n",
    "                best_features = current_features\n",
    "                best_train_results = train_results\n",
    "                best_test_results = test_results\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(\"\\nBest Model: \")\n",
    "        print(\"Features: \", best_features)\n",
    "        print(\"Train Results: \", best_train_results)\n",
    "        print(\"Test Results: \", best_test_results)\n",
    "    \n",
    "    return best_model, best_train_results, best_test_results\n",
    "\n",
    "# method that formats results of different models in a dataframe\n",
    "def tabularize_model_metrics(train_result_list, test_result_list, model_names):\n",
    "    train_df = pd.DataFrame(train_result_list)\n",
    "    test_df = pd.DataFrame(test_result_list)\n",
    "    train_df = train_df.rename(columns={\"adjusted_r_2\": \"Train Adjusted R2\", \"r_2\": \"Train R2\", \"mse\": \"Train Mean Sq Error\"})\n",
    "    test_df = test_df.rename(columns={\"adjusted_r_2\": \"Test Adjusted R2\", \"r_2\": \"Test R2\", \"mse\": \"Test Mean Sq Error\"})\n",
    "    df = pd.concat([train_df, test_df], axis=1)\n",
    "    df[\"Model\"] = model_names\n",
    "    return df[[\"Model\", \"Train Mean Sq Error\", \"Test Mean Sq Error\", \"Train R2\", \"Test R2\", \"Train Adjusted R2\", \"Test Adjusted R2\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that are dropped \n",
    "to_filter = [\"id\", \"zeit\", \"postleitzahl\", \"gemeinde\", \"bezirk\", \"geburtsjahr\",\n",
    "              \"is_missing_schaetzwert_bp_sys\", \"is_missing_schaetzwert_by_dia\", \"terminal\"]\n",
    "data_df, cat_feat_list, num_feat_list = format_variables(data_df, to_filter=to_filter)\n",
    "\n",
    "# one hot encoding cat variables to prep data for Decision Tree\n",
    "# ordinal variables and nominal are treated the same in trees, but need to be careful in Lin models\n",
    "\n",
    "encoded_data_df = encode_data(data_df, cat_feat_list, num_feat_list)\n",
    "encoded_train_set, encoded_test_set = train_test_split(encoded_data_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  10381\n",
      "Size of testing data:  4450\n",
      "Features used:  Index(['bundesland', 'befinden', 'geschlecht', 'raucher', 'blutzucker_bekannt',\n",
      "       'cholesterin_bekannt', 'in_behandlung', 'schaetzwert_bp_sys',\n",
      "       'schaetzwert_by_dia', 'messwert_bp_sys', 'messwert_bp_dia',\n",
      "       'is_local_resident', 'age', 'age_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data: \", len(encoded_train_set))\n",
    "print(\"Size of testing data: \", len(encoded_test_set))\n",
    "print(\"Features used: \", data_df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    " - scikit-learn uses an optimized version of the CART algorithm, does not support categorical variables\n",
    " - BIC cannot be computed as it depends on likelihood, cannot compute that for RegressionTree as it does not assume a conditional dist of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using self evaluated sys bp for analysis\n",
    "target = \"messwert_bp_sys\"\n",
    "\n",
    "# splitting targets from predictors\n",
    "X_train, Y_train = separate_target(encoded_train_set, target)\n",
    "X_test, Y_test = separate_target(encoded_test_set, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for DecisonTreeRegressor using all available features and default parameters\n",
    "\n",
    "train_results_tree_base, test_results_tree_base, model_tree_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\", {\"criterion\" : \"squared_error\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting base model for RandomForestRegressor using all available features and default parameters\n",
    "\n",
    "train_results_rf_base, test_results_rf_base, model_rf_base = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\", {\"criterion\" : \"squared_error\",\n",
    "                                                                                                                    \"n_estimators\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;, &#x27;sqrt&#x27;, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 6, 11, 16, 21],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;, &#x27;sqrt&#x27;, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.0],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [1, 6, 11, 16, 21],\n",
       "                         'max_features': ['auto', 'log2', 'sqrt', None],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46, 51, 56, 61, 66, 71, 76, 81,\n",
       "                                              86, 91, 96],\n",
       "                         'min_weight_fraction_leaf': [0.0],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the best set of parameters to use by finetuning RegTree using CV, fine-tuning is done on whole dataset\n",
    "\n",
    "parameters= {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : list(np.arange(1, 25, 5, dtype=int)),\n",
    "           \"min_samples_leaf\":list(np.arange(1, 100, 5, dtype=int)),\n",
    "           \"min_weight_fraction_leaf\":list(np.arange(0, 1, 1.0, dtype=float)),\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\", None]\n",
    "           }\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "X_train_full, Y_train_full = separate_target(encoded_data_df, target)\n",
    "tuning_model = GridSearchCV(model, param_grid=parameters, scoring='neg_mean_squared_error',cv=10,verbose=0)\n",
    "tuning_model.fit(X_train_full, Y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 66,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for DecisonTreeRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "\n",
    "train_results_tree_fine, test_results_tree_fine, model_tree_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressor\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting fine_tuned model for RandomForestRegressor using all available features and fine_tuned parameters\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "del model_params[\"splitter\"]\n",
    "model_params[\"n_estimators\"] = 100\n",
    "\n",
    "train_results_rf_fine, test_results_rf_fine, model_rf_fine = fit_model(X_train, Y_train, X_test, Y_test,\n",
    "                                                                              \"DecisionTreeRegressorRandomForest\",\n",
    "                                                                              model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting criterion for best subset selection\n",
    "BEST_SUBSET_CRITERION = \"mse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: \n",
      "Features:  ['messwert_bp_dia']\n",
      "Train Results:  {'r_2': -0.19055570853385229, 'adjusted_r_2': -0.19067041666647921, 'mse': 202.3280427992853}\n",
      "Test Results:  {'r_2': -0.2710051773240114, 'adjusted_r_2': -0.2712909248908557, 'mse': 208.34464192287473}\n"
     ]
    }
   ],
   "source": [
    "# using best subset selection with default parameters for DecisionTreeRegressor\n",
    "\n",
    "model_type = \"DecisionTreeRegressor\"\n",
    "model_params = {}\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "criterion = BEST_SUBSET_CRITERION\n",
    "features = list(X_train.columns)\n",
    "\n",
    "model_tree_base_best, train_results_tree_base_best, test_results_tree_base_best = best_subset_selection(features, criterion, X_train, Y_train, X_test, Y_test,\n",
    "                                                     model_type, model_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: \n",
      "Features:  ['bundesland_Vorarlberg', 'bundesland_Wien', 'bundesland_not applicable', 'befinden_2', 'befinden_3', 'befinden_4', 'befinden_5', 'geschlecht_m', 'raucher_True', 'blutzucker_bekannt_True', 'cholesterin_bekannt_True', 'in_behandlung_True', 'is_local_resident_True', 'age_group_adult', 'age_group_teenager', 'schaetzwert_bp_sys', 'schaetzwert_by_dia', 'messwert_bp_dia', 'age']\n",
      "Train Results:  {'r_2': 0.9036617935659197, 'adjusted_r_2': 0.9034851285796975, 'mse': 26.60463208309184}\n",
      "Test Results:  {'r_2': 0.18024607732305697, 'adjusted_r_2': 0.17673020271112416, 'mse': 183.376144932512}\n"
     ]
    }
   ],
   "source": [
    "# using best subset selection with default parameters for DecisionTreeRegressorRandomForest\n",
    "model_params = {}\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "model_params[\"n_estimators\"] = 100\n",
    "model_type = \"DecisionTreeRegressorRandomForest\"\n",
    "criterion = BEST_SUBSET_CRITERION\n",
    "features = list(X_train.columns)\n",
    "model_rf_base_best, train_results_rf_base_best, test_results_rf_base_best = best_subset_selection(features, criterion, X_train, Y_train, X_test, Y_test,\n",
    "                                                     model_type, model_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: \n",
      "Features:  ['schaetzwert_bp_sys', 'schaetzwert_by_dia', 'messwert_bp_dia', 'age']\n",
      "Train Results:  {'r_2': 0.1913485408422585, 'adjusted_r_2': 0.19103680165214376, 'mse': 166.44361989036423}\n",
      "Test Results:  {'r_2': 0.12538164915665018, 'adjusted_r_2': 0.12459459102315784, 'mse': 178.33355743654016}\n"
     ]
    }
   ],
   "source": [
    "# using best subset selection with finetuned parameters for DecisionTreeRegressor\n",
    "\n",
    "model_type = \"DecisionTreeRegressor\"\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "model_params[\"criterion\"] = \"squared_error\"\n",
    "criterion = BEST_SUBSET_CRITERION\n",
    "features = list(X_train.columns)\n",
    "\n",
    "model_tree_fine_best, train_results_tree_fine_best, test_results_tree_fine_best = best_subset_selection(features, criterion, X_train, Y_train, X_test, Y_test,\n",
    "                                                     model_type, model_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: \n",
      "Features:  ['befinden_3', 'befinden_4', 'befinden_5', 'geschlecht_m', 'raucher_True', 'blutzucker_bekannt_True', 'cholesterin_bekannt_True', 'in_behandlung_True', 'is_local_resident_True', 'age_group_adult', 'age_group_teenager', 'schaetzwert_bp_sys', 'schaetzwert_by_dia', 'messwert_bp_dia', 'age']\n",
      "Train Results:  {'r_2': 0.16916897471651082, 'adjusted_r_2': 0.1679666143325984, 'mse': 163.75304239926163}\n",
      "Test Results:  {'r_2': 0.11222288545170755, 'adjusted_r_2': 0.10921957992211251, 'mse': 173.14674199095273}\n"
     ]
    }
   ],
   "source": [
    "# using best subset selection with finetuned parameters for DecisionTreeRegressorRF\n",
    "\n",
    "model_type = \"DecisionTreeRegressorRandomForest\"\n",
    "model_params = tuning_model.best_params_.copy()\n",
    "del model_params[\"splitter\"]\n",
    "model_params[\"n_estimators\"] = 100\n",
    "criterion = BEST_SUBSET_CRITERION\n",
    "features = list(X_train.columns)\n",
    "model_rf_fine_best, train_results_rf_fine_best, test_results_rf_fine_best = best_subset_selection(features, criterion, X_train, Y_train, X_test, Y_test,\n",
    "                                                     model_type, model_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Mean Sq Error</th>\n",
       "      <th>Test Mean Sq Error</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train Adjusted R2</th>\n",
       "      <th>Test Adjusted R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree (Base)</td>\n",
       "      <td>1.476</td>\n",
       "      <td>361.268</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree (Fine-tuned)</td>\n",
       "      <td>164.102</td>\n",
       "      <td>178.981</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree (Best Subset + Base)</td>\n",
       "      <td>202.328</td>\n",
       "      <td>208.345</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree (Best Subset + Fine-tuned)</td>\n",
       "      <td>166.444</td>\n",
       "      <td>178.334</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF (Base)</td>\n",
       "      <td>26.434</td>\n",
       "      <td>184.895</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF (Fine-tuned)</td>\n",
       "      <td>163.389</td>\n",
       "      <td>173.029</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF (Best Subset + Base)</td>\n",
       "      <td>26.605</td>\n",
       "      <td>183.376</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF (Best Subset + Fine-tuned)</td>\n",
       "      <td>163.753</td>\n",
       "      <td>173.147</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Train Mean Sq Error  Test Mean Sq Error   \n",
       "0                      Tree (Base)                1.476             361.268  \\\n",
       "1                Tree (Fine-tuned)              164.102             178.981   \n",
       "2        Tree (Best Subset + Base)              202.328             208.345   \n",
       "3  Tree (Best Subset + Fine-tuned)              166.444             178.334   \n",
       "4                        RF (Base)               26.434             184.895   \n",
       "5                  RF (Fine-tuned)              163.389             173.029   \n",
       "6          RF (Best Subset + Base)               26.605             183.376   \n",
       "7    RF (Best Subset + Fine-tuned)              163.753             173.147   \n",
       "\n",
       "   Train R2  Test R2  Train Adjusted R2  Test Adjusted R2  \n",
       "0     0.996    0.107              0.996             0.102  \n",
       "1     0.212    0.133              0.210             0.128  \n",
       "2    -0.191   -0.271             -0.191            -0.271  \n",
       "3     0.191    0.125              0.191             0.125  \n",
       "4     0.905    0.179              0.904             0.175  \n",
       "5     0.168    0.110              0.166             0.105  \n",
       "6     0.904    0.180              0.903             0.177  \n",
       "7     0.169    0.112              0.168             0.109  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_list = [train_results_tree_base, train_results_tree_fine, train_results_tree_base_best, train_results_tree_fine_best,\n",
    "                     train_results_rf_base, train_results_rf_fine, train_results_rf_base_best, train_results_rf_fine_best]\n",
    "\n",
    "test_result_list = [test_results_tree_base, test_results_tree_fine, test_results_tree_base_best, test_results_tree_fine_best,\n",
    "                     test_results_rf_base, test_results_rf_fine, test_results_rf_base_best, test_results_rf_fine_best]\n",
    "\n",
    "model_names = [\"Tree (Base)\", \"Tree (Fine-tuned)\", \"Tree (Best Subset + Base)\", \"Tree (Best Subset + Fine-tuned)\",\n",
    "               \"RF (Base)\", \"RF (Fine-tuned)\", \"RF (Best Subset + Base)\", \"RF (Best Subset + Fine-tuned)\"]\n",
    "\n",
    "tab = tabularize_model_metrics(train_result_list, test_result_list, model_names)\n",
    "round(tab, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
